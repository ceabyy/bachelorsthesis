2025-10-23 07:22:31,604 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.3.4.9
	PyTorch: 2.9.0
	TorchVision: 0.24.0
2025-10-23 07:22:31,604 INFO: 
  name: test_oapt_gray
  model_type: OAPT_ModelB
  scale: 1
  num_gpu: 0
  manual_seed: 0
  tile:[
    tile_size: 224
    tile_pad: 16
  ]
  datasets:[
    test_1:[
      name: DIV2K_gray
      type: DoubleJpegImageDataset
      dataroot_gt: //Users/ceabyfernandez/bachelorsthesis/Datasets/DIV2K/DIV2K_train_HR_mini_gray
      dataroot_lq: /Users/ceabyfernandez/bachelorsthesis/Datasets/DIV2K/DIV2K_train_HR_mini_double_compressed_50_gray
      io_backend:[
        type: disk
      ]
      num_channels: 1
      color: y
      quality_factor: 50
      double_compression: True
      second_qfs: 70
      shift_w: 4
      shift_h: 4
      phase: test
      scale: 1
    ]
  ]
  network_g:[
    type: OAPT
    predictor_type: resnet18_small
    upscale: 1
    in_chans: 1
    img_size: 224
    window_size: 7
    DenseFirstPositions: True
    mode: non-interval
    img_range: 255.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    upsampler: 
    resi_connection: 1conv
    offset_range: 7
  ]
  path:[
    pretrain_network_g: /Users/ceabyfernandez/bachelorsthesis/OAPT/oapt/weights/OAPT_Pfreeze_gray_non_aligned2.pth
    pretrain_network_g_pred: None
    pretrain_network_g_rest: None
    strict_load_g: True
    param_key_g: params_ema
    results_root: /Users/ceabyfernandez/bachelorsthesis/OAPT/results/test_oapt_gray
    log: /Users/ceabyfernandez/bachelorsthesis/OAPT/results/test_oapt_gray
    visualization: /Users/ceabyfernandez/bachelorsthesis/OAPT/results/test_oapt_gray/visualization
  ]
  val:[
    save_img: True
    suffix: None
    pbar: True
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 0
        test_y_channel: False
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 0
        test_y_channel: False
      ]
    ]
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: False
  is_train: False

2025-10-23 07:22:31,605 INFO: Dataset [DoubleJpegImageDataset] - DIV2K_gray is built.
2025-10-23 07:22:31,606 INFO: Number of test images in DIV2K_gray: 5
2025-10-23 07:22:31,821 INFO: Network [OAPT] is created.
2025-10-23 07:22:31,826 INFO: Network: OAPT, with parameters: 12,955,923
2025-10-23 07:22:31,826 INFO: OAPT(
  (prediction): ResNet18_small(
    (conv1): Sequential(
      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (layer1): Sequential(
      (0): ResBlock_small(
        (left): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
          (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
      (1): ResBlock_small(
        (left): Sequential(
          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
          (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): ResBlock_small(
        (left): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
          (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): ResBlock_small(
        (left): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
          (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): ResBlock_small(
        (left): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): ResBlock_small(
        (left): Sequential(
          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
          (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
    )
    (layer4): Sequential(
      (0): ResBlock_small(
        (left): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
          (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): ResBlock_small(
        (left): Sequential(
          (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (3): ReLU(inplace=True)
          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
          (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (shortcut): Sequential()
      )
    )
    (fc): Linear(in_features=512, out_features=64, bias=True)
    (fc2): Linear(in_features=64, out_features=2, bias=True)
    (sig): Sigmoid()
  )
  (restoration): OAPT_gt(
    (conv_first): Conv2d(1, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (patch_embed): PatchEmbed(
      (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
    )
    (patch_unembed): PatchUnEmbed()
    (pos_drop): Dropout(p=0.0, inplace=False)
    (layers): ModuleList(
      (0): RSTB(
        (residual_group): BasicLayer(
          dim=180, input_resolution=(224, 224), depth=6
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): Identity()
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.003)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.006)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.009)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.011)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.014)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (patch_embed): PatchEmbed()
        (patch_unembed): PatchUnEmbed()
      )
      (1): RSTB(
        (residual_group): BasicLayer(
          dim=180, input_resolution=(224, 224), depth=6
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.017)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.020)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.023)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.026)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.029)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.031)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (patch_embed): PatchEmbed()
        (patch_unembed): PatchUnEmbed()
      )
      (2): RSTB(
        (residual_group): BasicLayer(
          dim=180, input_resolution=(224, 224), depth=6
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.034)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.037)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.040)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.043)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.046)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.049)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (patch_embed): PatchEmbed()
        (patch_unembed): PatchUnEmbed()
      )
      (3): RSTB(
        (residual_group): BasicLayer(
          dim=180, input_resolution=(224, 224), depth=6
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.051)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.054)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.057)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.060)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.063)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.066)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (patch_embed): PatchEmbed()
        (patch_unembed): PatchUnEmbed()
      )
      (4): RSTB(
        (residual_group): BasicLayer(
          dim=180, input_resolution=(224, 224), depth=6
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.069)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.071)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.074)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.077)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.080)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.083)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (patch_embed): PatchEmbed()
        (patch_unembed): PatchUnEmbed()
      )
      (5): RSTB(
        (residual_group): BasicLayer(
          dim=180, input_resolution=(224, 224), depth=6
          (blocks): ModuleList(
            (0): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.086)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.089)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.091)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.094)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.097)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): SwinTransformerBlock(
              (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (attn): WindowAttention(
                dim=180, window_size=(7, 7), num_heads=6
                (qkv): Linear(in_features=180, out_features=540, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=180, out_features=180, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (softmax): Softmax(dim=-1)
              )
              (drop_path): DropPath(drop_prob=0.100)
              (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=180, out_features=360, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=360, out_features=180, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (patch_embed): PatchEmbed()
        (patch_unembed): PatchUnEmbed()
      )
    )
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
    (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv_last): Conv2d(180, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
)
2025-10-23 07:22:32,013 INFO: Loading OAPT model from /Users/ceabyfernandez/bachelorsthesis/OAPT/oapt/weights/OAPT_Pfreeze_gray_non_aligned2.pth, with param key: [params_ema].
2025-10-23 07:22:32,067 INFO: Model [OAPT_ModelB] is created.
2025-10-23 07:22:32,067 INFO: Testing DIV2K_gray...
2025-10-23 08:08:02,663 INFO: Validation DIV2K_gray
	 # psnr: 36.1697	Best: 36.1697 @ test_oapt_gray iter
	 # ssim: 0.9645	Best: 0.9645 @ test_oapt_gray iter

2025-10-23 08:08:02,665 INFO: out_img: psnrb=36.0756
2025-10-23 08:08:02,665 INFO: lq_img: psnr=35.6716;  ssim=0.9573;   psnrb=34.1984

